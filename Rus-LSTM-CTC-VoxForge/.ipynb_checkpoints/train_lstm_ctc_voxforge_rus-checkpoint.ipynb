{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "# from utils import read_wav, extract_feats, read_dataset, batch, decode\n",
    "from IPython.display import Audio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.core.display import HTML\n",
    "from scipy.signal import spectrogram\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import fbank, mfcc\n",
    "import time\n",
    "\n",
    "#from itertools import izip_longest as zip_longest\n",
    "\n",
    "from keras.layers import LSTM, Dense, Convolution1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers.wrappers import TimeDistributed, Bidirectional\n",
    "from itertools import zip_longest\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(d, mapping):\n",
    "    \"\"\"Decode.\"\"\"\n",
    "    shape = d.dense_shape\n",
    "    batch_size = shape[0]\n",
    "    ans = np.zeros(shape=shape, dtype=int)\n",
    "    seq_lengths = np.zeros(shape=(batch_size, ), dtype=np.int)\n",
    "    for ind, val in zip(d.indices, d.values):\n",
    "        ans[ind[0], ind[1]] = val\n",
    "        seq_lengths[ind[0]] = max(seq_lengths[ind[0]], ind[1] + 1)\n",
    "    ret = []\n",
    "    for i in range(batch_size):\n",
    "        ret.append(\"\".join(map(lambda s: mapping[s], ans[i, :seq_lengths[i]])))\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_2d_to_sparse(list_of_lists):\n",
    "    \"\"\"Convert python list of lists to a [tf.SparseTensorValue](https://www.tensorflow.org/api_docs/python/tf/SparseTensorValue).\n",
    "\n",
    "    Args:\n",
    "        list_of_lists: list of lists to convert.\n",
    "\n",
    "    Returns:\n",
    "        tf.SparseTensorValue which is a namedtuple (indices, values, shape) where:\n",
    "\n",
    "            * indices is a 2-d numpy array with shape (sum_all, 2) where sum_all is a\n",
    "            sum over i of len(l[i])\n",
    "\n",
    "            * values is a 1-d numpy array with shape (sum_all, )\n",
    "0\n",
    "            * shape = np.array([len(l), max_all]) where max_all is a max over i of\n",
    "            len(l[i])\n",
    "\n",
    "        Also, the following is true: for all i values[i] ==\n",
    "        list_of_lists[indices[i][0]][indices[i][1]]\n",
    "\n",
    "    \"\"\"\n",
    "    indices, values = [], []\n",
    "    for i, sublist in enumerate(list_of_lists):\n",
    "        for j, value in enumerate(sublist):\n",
    "            indices.append([i, j])\n",
    "            values.append(value)\n",
    "    dense_shape = [len(list_of_lists), max(map(len, list_of_lists))]\n",
    "    return tf.SparseTensorValue(indices=np.array(indices),\n",
    "                                values=np.array(values),\n",
    "                                dense_shape=np.array(dense_shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = { 'а': 1,\n",
    "               'б': 2,\n",
    "               'в': 3,\n",
    "               'г': 4,\n",
    "               'д': 5,\n",
    "               'е': 6,\n",
    "               'ё': 7,\n",
    "               'ж': 8,\n",
    "               'з': 9,\n",
    "               'и': 10,\n",
    "               'й': 11,\n",
    "               'к': 12,\n",
    "               'л': 13,\n",
    "               'м': 14,\n",
    "               'н': 15,\n",
    "               'о': 16,\n",
    "               'п': 17,\n",
    "               'р': 18,\n",
    "               'с': 19,\n",
    "               'т': 20,\n",
    "               'у': 21,\n",
    "               'ф': 22,\n",
    "               'х': 23,\n",
    "               'ц': 24,\n",
    "               'ч': 25,\n",
    "               'ш': 26,\n",
    "               'щ': 27,\n",
    "               'ъ': 28,\n",
    "               'ы': 29,\n",
    "               'ь': 30,\n",
    "               'э': 31,\n",
    "               'ю': 32,\n",
    "               'я': 33}\n",
    "\n",
    "inv_mapping = dict(zip(vocabulary.values(), vocabulary.keys()))\n",
    "inv_mapping[34]='<пробел>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Каталог с базой аудио\n",
    "voxforge_dir = './Voxforge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_folders = os.listdir(voxforge_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_folders1=[]\n",
    "x=0\n",
    "for i in speaker_folders:\n",
    "    speaker_folders1.append(i)\n",
    "    x=x+1\n",
    "    if x>75:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_folders1[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_for_speaker(speaker, folder):\n",
    "    \"\"\"\n",
    "    Generates a list of wav files for a given speaker from the voxforge dataset.\n",
    "    Args:\n",
    "        speaker: substring contained in the speaker's folder name, e.g. 'Aaron'\n",
    "        folder: base folder containing the downloaded voxforge data\n",
    "\n",
    "    Returns: list of paths to the wavfiles\n",
    "    \"\"\"\n",
    "\n",
    "    speaker_folders = [d for d in os.listdir(folder) if speaker in d]\n",
    "    wav_files = []\n",
    "\n",
    "    for d in speaker_folders:\n",
    "        for f in os.listdir(os.path.join(folder, d, 'wav')):\n",
    "            wav_files.append(os.path.abspath(os.path.join(folder, d, 'wav', f)))\n",
    "\n",
    "    return wav_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_targets(wav_file):\n",
    "    #wav=[]\n",
    "#     обработка текст\n",
    "    txt_file = wav_file.replace('/wav/', '/txt/').replace('.wav', '.txt')\n",
    "    try:\n",
    "       # print(txt_file)\n",
    "        f = open(txt_file, 'rb')\n",
    "    except IOError as e:\n",
    "#         print(u'не удалось открыть файл')\n",
    "        return 0,0,0,0\n",
    "    else:\n",
    "        with f:\n",
    "#     with open(txt_file, 'rb') as f:\n",
    "            for line in f.readlines():\n",
    "                if line[0] == ';':\n",
    "                    continue\n",
    "\n",
    "            # Get only the words between [a-z] and replace period for none\n",
    "            \n",
    "            original = ' '.join(str(line,'utf-8').strip().lower().split(' ')).replace('.', '').replace(\"'\", '').replace('-', '').replace(',','')\n",
    "            targets = original.replace(' ', '  ')\n",
    "            targets = targets.split(' ')\n",
    "            stroka=[34]\n",
    "\n",
    "            for i in targets:\n",
    "                i1=i.encode(\"UTF-8\")\n",
    "                for j in range(0,len(i1),2):\n",
    "                    stroka.append(vocabulary.get(i1[j:j+2].decode(\"utf-8\"),34))\n",
    "                if stroka[-1] != 34:\n",
    "                    stroka.append(34)\n",
    "#                     обработка звука\n",
    "            fs, audio = wav.read(wav_file)\n",
    "\n",
    "            features = mfcc(audio, samplerate=fs, lowfreq=50)\n",
    "\n",
    "            mean_scale = np.mean(features, axis=0)\n",
    "            std_scale = np.std(features, axis=0)\n",
    "\n",
    "            features = (features - mean_scale[np.newaxis, :]) / std_scale[np.newaxis, :]\n",
    "\n",
    "            seq_len = features.shape[0]\n",
    "            return features, stroka, seq_len, original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготавливаем данные для обучения - примерно 3Гб\n",
    "X = []\n",
    "y = []\n",
    "for j in speaker_folders1:\n",
    "    wav_files = list_files_for_speaker(j, voxforge_dir)\n",
    "    for i in wav_files:\n",
    "        #i=i.encode('utf-8')\n",
    "        features, stroka, seq_len, original=extract_features_and_targets(i)\n",
    "        if seq_len !=0 :\n",
    "            X.append(features)\n",
    "            y.append(stroka)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[1][41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x[1][6][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode1(stroka,inv_mapping):\n",
    "    ret = []\n",
    "    for i in range(len(stroka)):\n",
    "         ret.append(\"\".join( inv_mapping.get(int(stroka[i]),34)))\n",
    "    for i in range(len(ret)):\n",
    "        print(str(ret[i])),\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decode1(stroka,inv_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(X_train, y_train, batch_size):\n",
    "    num_features = X_train[0].shape[1]\n",
    "    n = len(X_train)\n",
    "    perm = np.random.permutation(n)\n",
    "    for batch_ind in np.resize(perm, (n // batch_size, batch_size)):\n",
    "        X_batch, y_batch = [X_train[i] for i in batch_ind], [y_train[i] for i in batch_ind]\n",
    "        sequence_lengths = list(map(len, X_batch))\n",
    "        X_batch_padded = np.array(list(zip_longest(*X_batch, fillvalue=np.zeros(num_features)))).transpose([1, 0, 2])\n",
    "        yield X_batch_padded, sequence_lengths, list_2d_to_sparse(y_batch), y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inv_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    input_X = tf.placeholder(tf.float32, shape=[None, None, 13],name=\"input_X\")\n",
    "    labels = tf.sparse_placeholder(tf.int32)\n",
    "    seq_lens = tf.placeholder(tf.int32, shape=[None],name=\"seq_lens\")\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True, implementation=2), input_shape=(None, 13)))\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True, implementation=2)))\n",
    "    model.add(TimeDistributed\n",
    "              (Dense(len(inv_mapping) + 2)))\n",
    "    \n",
    "    final_seq_lens = seq_lens\n",
    "\n",
    "    logits = model(input_X)\n",
    "    logits = tf.transpose(logits, [1, 0, 2])\n",
    "\n",
    "    ctc_loss = tf.reduce_mean(tf.nn.ctc_loss(labels, logits, final_seq_lens))\n",
    "    # ctc_greedy_decoder? merge_repeated=True\n",
    "    decoded, log_prob = tf.nn.ctc_greedy_decoder(logits, final_seq_lens)\n",
    "    ler = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32), labels))\n",
    "\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(ctc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=181\n",
    "epoch_save_step=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаемся в начале на коротких данных \n",
    "y_train1=[]\n",
    "X_train1=[]\n",
    "for i in range(len(y)):\n",
    "    if len(y[i]) <75:\n",
    "        y_train1.append(y[i])\n",
    "        X_train1.append(X[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот отсюда не чего не понятно, код написан на пионе втором , и тензор тоже неизвестно какой версии, я впринцепе большую часть всего перепеал под третий, а дальше не могу понять что происходит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    print(\"----------------------------------------------------\")\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    snapshot = \"ctc\"\n",
    "    checkpoint = tf.train.latest_checkpoint(checkpoint_dir=\"checkpoint1\")\n",
    "    last_epoch = 0\n",
    "    \n",
    "    if checkpoint:\n",
    "        \n",
    "        print(\"[i] LOADING checkpoint \" + checkpoint)\n",
    "        try:\n",
    "            saver.restore(session, checkpoint)\n",
    "            last_epoch = int(checkpoint.split('-')[-1]) + 1\n",
    "            print(\"[i] start from epoch %d\" % last_epoch)\n",
    "        except:\n",
    "            print(\"[!] incompatible checkpoint, restarting from 0\")\n",
    "    else:\n",
    "        # Initializate the weights and biases\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "\n",
    "    for epoch in range(last_epoch, num_epochs):\n",
    "        for X_batch, seq_lens_batch, y_batch, y_batch_orig in batch(X_train1, y_train1, 100):\n",
    "            feed_dict = {\n",
    "                input_X: X_batch,\n",
    "                labels: y_batch,\n",
    "\n",
    "                seq_lens: seq_lens_batch\n",
    "            }\n",
    "            train_loss, train_ler, train_decoded, true, _ = session.run([ctc_loss, ler, decoded[0], labels, train_op], feed_dict=feed_dict)\n",
    "        if epoch % epoch_save_step == 0 and epoch > 0:\n",
    "                print(\"[i] SAVING snapshot %s\" % snapshot)\n",
    "#                 del tf.get_collection_ref ( ' LAYER_NAME_UIDS ' )[ 0 ]\n",
    "                saver.save(session, \"checkpoint1/\" + snapshot + \".ckpt\", epoch)\n",
    "\n",
    "#         for X_batch, seq_lens_batch, y_batch, y_batch_orig in batch(X_test, y_test, 4):\n",
    "#             feed_dict = {\n",
    "#                 input_X: X_batch,\n",
    "#                 labels: y_batch,\n",
    "#                 seq_lens: seq_lens_batch\n",
    "#             }\n",
    "#             test_loss, test_ler, test_decoded, true = session.run([ctc_loss, ler, decoded[0], labels], feed_dict=feed_dict)\n",
    "        print(epoch, train_loss, train_ler)#,  test_loss, test_ler)\n",
    "        ret=decode(train_decoded, inv_mapping)[:10]\n",
    "        for i in range(len(ret)):\n",
    "            print(str(ret[i])),\n",
    "        print(time.ctime())\n",
    "        decode1(y_batch_orig[0],inv_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаемся на средних данных (длина предложения меньше 181 символа)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# y_train1=[]\n",
    "# X_train1=[]\n",
    "# for i in range(len(y)):\n",
    "#     if len(y[i]) <181:\n",
    "#         y_train1.append(y[i])\n",
    "#         X_train1.append(X[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у Вас мощный компьютер, можно обучиться на полных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-c7bb2bc52c9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_lens_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch_orig\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             feed_dict = {\n\u001b[0;32m     26\u001b[0m                 \u001b[0minput_X\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-bd247e87a12b>\u001b[0m in \u001b[0;36mbatch\u001b[1;34m(X_train, y_train, batch_size)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mnum_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mperm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_ind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "num_epochs=1000\n",
    "epoch_save_step=5\n",
    "with tf.Session(graph=graph) as session:\n",
    "\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    snapshot = \"ctc\"\n",
    "    checkpoint = tf.train.latest_checkpoint(checkpoint_dir=\"checkpoint1\")\n",
    "    last_epoch = 0\n",
    "\n",
    "    if checkpoint:\n",
    "        print(\"[i] LOADING checkpoint \" + checkpoint)\n",
    "        try:\n",
    "            saver.restore(session, checkpoint)\n",
    "            last_epoch = int(checkpoint.split('-')[-1]) + 1\n",
    "            print(\"[i] start from epoch %d\" % last_epoch)\n",
    "        except:\n",
    "            print(\"[!] incompatible checkpoint, restarting from 0\")\n",
    "    else:\n",
    "        # Initializate the weights and biases\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "\n",
    "    for epoch in range(last_epoch, num_epochs):\n",
    "        for X_batch, seq_lens_batch, y_batch, y_batch_orig in batch(X, y, 4):\n",
    "            feed_dict = {\n",
    "                input_X: X_batch,\n",
    "                labels: y_batch,\n",
    "\n",
    "                seq_lens: seq_lens_batch\n",
    "            }\n",
    "            train_loss, train_ler, train_decoded, true, _ = session.run([ctc_loss, ler, decoded[0], labels, train_op], feed_dict=feed_dict)\n",
    "        if epoch % epoch_save_step == 0 and epoch > 0:\n",
    "                print(\"[i] SAVING snapshot %s\" % snapshot)\n",
    "#                 del tf.get_collection_ref ( ' LAYER_NAME_UIDS ' )[ 0 ]\n",
    "                saver.save(session, \"checkpoint1/\" + snapshot + \".ckpt\", epoch)\n",
    "\n",
    "#         for X_batch, seq_lens_batch, y_batch, y_batch_orig in batch(X_test, y_test, 4):\n",
    "#             feed_dict = {\n",
    "#                 input_X: X_batch,\n",
    "#                 labels: y_batch,\n",
    "#                 seq_lens: seq_lens_batch\n",
    "#             }\n",
    "#             test_loss, test_ler, test_decoded, true = session.run([ctc_loss, ler, decoded[0], labels], feed_dict=feed_dict)\n",
    "        print(epoch, train_loss, train_ler)#,  test_loss, test_ler)\n",
    "        ret=decode(train_decoded, inv_mapping)[:10]\n",
    "        for i in range(len(ret)):\n",
    "            print(str(ret[i])),\n",
    "        print(time.ctime())\n",
    "        decode1(y_batch_orig[0],inv_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
