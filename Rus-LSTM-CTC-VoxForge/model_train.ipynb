{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключаем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Библиотека, которая позволяет создавать модели нейронных сетей \n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Позволяет создать массив фреймов аудиопотока \n",
    "import numpy as np\n",
    "import os\n",
    "# Связанные с numpy\n",
    "from IPython.display import Audio\n",
    "from IPython.core.display import HTML\n",
    "# Библиотека, которая позволяет рисовать спектрограмму частоты звука от времени\n",
    "# Работает с преобразованием Фурье \n",
    "from scipy.signal import spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Все еще подключаем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для парсинга wav-файлов \n",
    "import scipy.io.wavfile as wav\n",
    "# Мел частотные кепстральные коэффициенты (спектрограмма с мел-шкалой вместо оси у)\n",
    "# Строит характеристику частот от времени в сэмплах через STFT \n",
    "from python_speech_features import fbank, mfcc\n",
    "import time\n",
    "# LSTM - для вызова рекурсивной функции\n",
    "# Dense - для связи всех нейронов предыдущего слоя с текущим (выходным) слоем\n",
    "# Convolution - сверта слоев\n",
    "from keras.layers import LSTM, Dense, Convolution1D\n",
    "# Позволяет давать послойное описание модели \n",
    "from keras.models import Sequential\n",
    "# TimeDistributed - Один из способов работы с Dense \n",
    "# Bidirectional - получение информации не только от прошлого и самого себя, но от будущего  \n",
    "from keras.layers.wrappers import TimeDistributed, Bidirectional\n",
    "# Последовательность\n",
    "from itertools import zip_longest\n",
    "# Работа с графиками в jupyter \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция-декодер, принимает train_decoded и inv_mapping(?), возвращает(?) \n",
    "# что в ней происходит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d - train_decoded \n",
    "# mapping - inv_mapping\n",
    "def decode(d, mapping):\n",
    "# Определяет 1-D тензор \n",
    "    shape = d.dense_shape\n",
    "# batch_size определяет количество сэмплов, на которых учится НС  \n",
    "# В нашем случае НС будет учиться на выборке размера batch_size num_epochos (700) раз \n",
    "    batch_size = shape[0]\n",
    "# np.zeros возвращает новый тензор заданной формы и типа,\n",
    "# заполненный нулями\n",
    "    ans = np.zeros(shape=shape, dtype=int)\n",
    "# np.int можно сравнить с сишным лонгом\n",
    "# последовательнотсь длин батчей и дозаполнение нулями\n",
    "    seq_lengths = np.zeros(shape=(batch_size, ), dtype=np.int)\n",
    "    \n",
    "    \n",
    "# Пробегаемся по запакованным индексам и весам каждый индекс и вес          \n",
    "    for ind, val in zip(d.indices, d.values):\n",
    "# Берем индексы 0 и 1 второго слоя тензора SparseTensorValue train_decoded\n",
    "# и элементу с этими индексами в 2-D нулевом массиве присваем значение\n",
    "# val из train_decoded.values - 1-D вложенного тензора  \n",
    "        ans[ind[0], ind[1]] = val\n",
    "# очередь длин - берем максимум из  соседнего с seq_lengths[ind[0]] элемента \n",
    "# ind[0] = train_decoded.indices[0], т.к. indices - 2-D тензор \n",
    "        el = seq_lengths[ind[0]] \n",
    "        el = max(el, ind[1] + 1)\n",
    "    ret = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "# Принимает массив         \n",
    "        ret.append(\"\".join(map(lambda s: mapping[s], ans[i, :seq_lengths[i]])))\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "print(a[0] + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция, которая преобразует входящие данные \n",
    "# (список списков list_of_lists) к тензору  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_2d_to_sparse(list_of_lists):\n",
    "# Преобразуем список списков к виду tf.SparseTensorValue(indices, values, shape)\n",
    "# indices - 2-D тензор формы [N, ndims], который уточняет значения индексов для тензора с весами \n",
    "# (ненулевые индексы)\n",
    "# values - 1-D тензор с данными любого типа и формой[N], который содержит значения весов для   \n",
    "# каждого элемента с индексами из indices \n",
    "# shape - 1-D int64 тензор формы[ndims], который определяет форму тензора. Берет список, индексующий\n",
    "# элементы в каждом измерении \n",
    "    indices, values = [], []\n",
    "    for i, sublist in enumerate(list_of_lists):\n",
    "        for j, value in enumerate(sublist):\n",
    "            indices.append([i, j])\n",
    "            values.append(value)\n",
    "#   Привет, Кирилл. Сейчас 6 утра и следующие комменты тебя повеселят. Но мне нихрена не смешно :(\n",
    "# max(map(len, list_of_lists)) - максимальная длина списка из списка списков\n",
    "# dense_shape = [длина списка списков, максимальная длина списка из списка списков]     \n",
    "    dense_shape = [len(list_of_lists), max(map(len, list_of_lists))]\n",
    "# переводим данные в сишный лонг\n",
    "    return tf.SparseTensorValue(indices = np.array(indices),\n",
    "                                values = np.array(values),\n",
    "                                dense_shape = np.array(dense_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Словарь для побуквенного распознавания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = { 'а': 1,\n",
    "               'б': 2,\n",
    "               'в': 3,\n",
    "               'г': 4,\n",
    "               'д': 5,\n",
    "               'е': 6,\n",
    "               'ё': 7,\n",
    "               'ж': 8,\n",
    "               'з': 9,\n",
    "               'и': 10,\n",
    "               'й': 11,\n",
    "               'к': 12,\n",
    "               'л': 13,\n",
    "               'м': 14,\n",
    "               'н': 15,\n",
    "               'о': 16,\n",
    "               'п': 17,\n",
    "               'р': 18,\n",
    "               'с': 19,\n",
    "               'т': 20,\n",
    "               'у': 21,\n",
    "               'ф': 22,\n",
    "               'х': 23,\n",
    "               'ц': 24,\n",
    "               'ч': 25,\n",
    "               'ш': 26,\n",
    "               'щ': 27,\n",
    "               'ъ': 28,\n",
    "               'ы': 29,\n",
    "               'ь': 30,\n",
    "               'э': 31,\n",
    "               'ю': 32,\n",
    "               'я': 33\n",
    "             }\n",
    "# Преобразование в словарь \n",
    "inv_mapping = dict(zip(vocabulary.values(), vocabulary.keys()))\n",
    "inv_mapping[34]='<пробел>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление каталога аудио"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Каталог с базой аудио\n",
    "voxforge_dir = './Voxforge'\n",
    "# Папки в каталоге\n",
    "speaker_folders = os.listdir(voxforge_dir)\n",
    "speaker_folders1=[]\n",
    "x=0\n",
    "# Делаем массив директорий к аудиофайлам\n",
    "for i in speaker_folders:\n",
    "    speaker_folders1.append(i)\n",
    "    x=x+1\n",
    "    if x>75:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем пути к аудиодорожкам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_for_speaker(speaker, folder):\n",
    "# Создает список wav-файлов для данного \"спикера\" из дата-сета (voxforge)\n",
    "# Список(подстрока, содержащая имя \"спикера\", имя папки)  \n",
    "    speaker_folders = [d for d in os.listdir(folder) if speaker in d]\n",
    "    wav_files = []\n",
    "# Загрузка аудиофайлов из датасета\n",
    "    for d in speaker_folders:\n",
    "        for f in os.listdir(os.path.join(folder, d, 'wav')):\n",
    "            wav_files.append(os.path.abspath(os.path.join(folder, d, 'wav', f)))\n",
    "# Возвращает список путей к wav файлам     \n",
    "    return wav_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ищем отличительные признаки в сэмплах "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_targets(wav_file):\n",
    "# wav=[]\n",
    "# Обработка текста\n",
    "# Форматирование (?) wav -> txt\n",
    "    txt_file = wav_file.replace('/wav/', '/txt/').replace('.wav', '.txt')\n",
    "    try:\n",
    "# txt_file - путь к файлу\n",
    "# заливаем в буфер\n",
    "        f = open(txt_file, 'rb')\n",
    "# Ошибка ввода-вывода \n",
    "# Input Output Error\n",
    "    except IOError as e:\n",
    "        print(\"Не удалось открыть файл\")\n",
    "        return 0,0,0,0\n",
    "    else:\n",
    "        with f:\n",
    "# Строка выше - все равно что with open(txt_file, 'rb') as f:\n",
    "# Построчно читаем файл             \n",
    "            for line in f.readlines():\n",
    "                if line[0] == ';':\n",
    "                    continue\n",
    "\n",
    "# Читаем только по словарю [а-я] и заменяем все знаки на пустоту\n",
    "            original = ' '.join(str(line, 'utf-8').strip().lower().split(' ')).replace('.', '').replace(\"'\", '').replace('-', '').replace(',','')\n",
    "# Меняем пробелы на более длинные \n",
    "            targets = original.replace(' ', '  ')\n",
    "# Разделяем слова через пробелы \n",
    "            targets = targets.split(' ')\n",
    "# Объявляем строку и начинаем ее с пробела\n",
    "            stroka=[34]\n",
    "            for i in targets:\n",
    "                i1=i.encode(\"UTF-8\")\n",
    "                for j in range(0,len(i1),2):\n",
    "# Через вызов decode() получаем буквы и добавляем их в строку \n",
    "                    stroka.append(vocabulary.get(i1[j:j+2].decode(\"utf-8\"),34))\n",
    "                if stroka[-1] != 34:\n",
    "# Закончили с буквами\n",
    "# Добавляем в конец строки пробел\n",
    "                    stroka.append(34)\n",
    "# Обработка звука\n",
    "            fs, audio = wav.read(wav_file)\n",
    "# Ищем отличительные черты через мел-кепстральные коэффициенты и преобразование Фурье            \n",
    "# Мел-шкала отражает главным образом высоту звука, от которой, в свою очередь, его частота. \n",
    "# Эта зависимость нелинейна, особенно при низких частотах.\n",
    "# Различные звуки имеют различные частоты и, соответственно, по-разному отображаются\n",
    "# на мел-шкале.\n",
    "\n",
    "\n",
    "            features = mfcc(audio, samplerate=fs, lowfreq=50)\n",
    "            mean_scale = np.mean(features, axis=0)\n",
    "            std_scale = np.std(features, axis=0)\n",
    "            \n",
    "            features = (features - mean_scale[np.newaxis, :]) / std_scale[np.newaxis, :]\n",
    "            seq_len = features.shape[0]\n",
    "            return features, stroka, seq_len, original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготавливаем данные для обучения - примерно 3Гб"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for j in speaker_folders1:\n",
    "    wav_files = list_files_for_speaker(j, voxforge_dir)\n",
    "    for i in wav_files:\n",
    "        #i=i.encode('utf-8')\n",
    "        features, stroka, seq_len, original = extract_features_and_targets(i)\n",
    "        if seq_len != 0:\n",
    "            X.append(features)\n",
    "            y.append(stroka)\n",
    "            \n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем генератор\n",
    "def batch(X_train, y_train, batch_size):\n",
    "# num_features = 13\n",
    "# 13 элементов в каждом (453) вложенном элементе X_train - в каждом i из X_train[i]  \n",
    "# по сути мы можем взять любой X_train[А] из 453 вариантов А и num_features не изменится \n",
    "    num_features = X_train[0].shape[1]\n",
    "    print(num_features)\n",
    "# Количество элементов в X_train-е (453)\n",
    "    n = len(X_train)\n",
    "# Создаем массив из последовательности 0..452 и перемешиваем его \n",
    "    perm = np.random.permutation(n)\n",
    "# batch_size = 100\n",
    "# n // batch_size = 4\n",
    " \n",
    "# Если мы отсортируем perm по возрастанию - получим массив 0..452     \n",
    "#     perm.sort()\n",
    "# если perm отсортирован по возрастанию, то\n",
    "# np.resize(perm, (n // batch_size, batch_size)) делает из  perm 2-D массив и разбивает его на 4\n",
    "# последовательности элементов от 100*а до 100*а+99, где а - целое число от 0 до 3\n",
    "# если мы не сортируем perm, то получим 2-D массив с 4 элементами, в которых лежат\n",
    "# неповторяющиеся числа от 0 до 452 по 100 в каждом элементе\n",
    "# Следующий цикл проходит 4 раза \n",
    "    for batch_ind in np.resize(perm, (n // batch_size, batch_size)):\n",
    "# batch_ind - элемент из resize-нутого perm-а (тот самый элемент, который состоит из 100 неповторяющихся\n",
    "# значений в диапазоне 0..452)\n",
    "# Т.е. мы берем каждый из элементов perm-а с индексом batch_ind, и т.к. batch_ind - индекс 2-D массива,\n",
    "# то он сам является массивом\n",
    "        print(batch_ind)\n",
    "# Следующий цикл проходит 100 раз\n",
    "# Мы берем первые 400 значений из X_train и записываем их в 2-D X_batch\n",
    "        for i in batch_ind:\n",
    "            X_batch = X_train[i]            \n",
    "#             for i in range(len(X_batch)):\n",
    "#                 print(X_batch)\n",
    "        for i in batch_ind:\n",
    "            y_batch = y_train[i] \n",
    "# циклы выше - то же. что и строка ниже \n",
    "# X_batch, y_batch = [X_train[i] for i in batch_ind], [y_train[i] for i in batch_ind]        \n",
    "# конструкция list(map(function, arg)), где function - функция, которая применяется \n",
    "# к каждому элементу arg - аргумента составного типа данных(в нашем случае 2-D массив),\n",
    "# равнозначна следующему коду:\n",
    "# old_lit = ['1' , '2' , '3']\n",
    "# new_list = []\n",
    "# for i in old_list:\n",
    "#     new_list.append(int(i))\n",
    "# но в нашем случае мы создаем новый список sequence_lengths из длин элементов 2-D массива\n",
    "        sequence_lengths = list(map(len, X_batch))  \n",
    "#         print(sequence_lengths)\n",
    "\n",
    "        X_batch_padded = np.array(list(zip_longest(*X_batch, fillvalue=np.zeros(num_features)))).transpose([1, 0, 2])\n",
    "# zip_longest() преобразует аргументы в значение типа zip\n",
    "# list(zip), где zip - переменная типа zip, повзоляет посмотреть, что именно лежит в переменной \n",
    "# (в целом, лист обратен зипу) \n",
    "\n",
    "# С учетом данных выше эту строку можно разложить так:\n",
    "# zipped_X_batches = zip_longest(*X_batch, fillvalue=np.zeros(num_features))\n",
    "# list_to_array = list(zipped_X_batches)\n",
    "# X_batch_padded = np.array(list_to_array)\n",
    " \n",
    "\n",
    "# !!!\n",
    "# зачем это происходит?\n",
    "\n",
    "# возвращаем данные \n",
    "        yield X_batch_padded, sequence_lengths, list_2d_to_sparse(y_batch), y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаемся в начале на коротких данных \n",
    "y_train1=[]\n",
    "X_train1=[]\n",
    "for i in range(len(y)):\n",
    "    if len(y[i]) <75:\n",
    "        y_train1.append(y[i])\n",
    "        X_train1.append(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_batch, seq_lens_batch, y_batch, y_batch_orig=batch(X_train1, y_train1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 13\n",
    "# batch_size = 100\n",
    "# perm = np.random.permutation(n)\n",
    "# y_train1=[]\n",
    "# X_train1=[]\n",
    "# for i in range(len(y)):\n",
    "#     if len(y[i]) < 75:\n",
    "#         y_train1.append(y[i])\n",
    "#         X_train1.append(X[i])\n",
    "# print(\"S\")\n",
    "# for batch_ind in np.resize(perm, (4, batch_size)):\n",
    "#     print(batch_ind.shape)\n",
    "#     print(len(batch_ind))\n",
    "#     print(batch_ind)\n",
    "#     x_batch = [X_train1[i] for i in batch_ind]\n",
    "#     # print(\"x_batch\", i, x_batch)\n",
    "#     y_batch = [y_train1[i] for i in batch_ind]\n",
    "#     # print(\"y_batch\", i, y_batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perm = np.random.permutation(n) \n",
    "# print(perm)\n",
    "# a = 100\n",
    "# n = 13\n",
    "# print(np.resize(perm, (n // a, a)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aa.resize((1,7))\n",
    "# print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_batch, seq_lens_batch, y_batch, y_batch_orig=batch(X_train1, y_train1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Модель нейронной сети -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x7f767a3edb38>\n",
      "Tensor(\"transpose:0\", shape=(?, ?, 36), dtype=float32)\n",
      "<keras.engine.sequential.Sequential object at 0x7f767a3edb38>\n"
     ]
    }
   ],
   "source": [
    "# Создание графа\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    input_X = tf.placeholder(tf.float32, shape=[None, None, 13],name=\"input_X\")\n",
    "    labels = tf.sparse_placeholder(tf.int32)\n",
    "    seq_lens = tf.placeholder(tf.int32, shape=[None],name=\"seq_lens\")\n",
    "\n",
    "# Sequential() \n",
    "    model = Sequential()\n",
    "#     LSTM(units, activation = 'tanh', recurrent_activation= 'sigmoid', use_bias = true,\n",
    "#          kernel_initializer = 'glorot_uniform', recurrent_initializer = 'orthogonal', \n",
    "#          bias_initializer = 'zeros', ... )\n",
    "# Слои двунаправленных нейронов \n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True, implementation=2), input_shape=(None, 13)))\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True, implementation=2)))\n",
    "# Выходной слой \n",
    "    model.add(TimeDistributed(Dense(len(inv_mapping) + 2)))\n",
    "    \n",
    "    final_seq_lens = seq_lens\n",
    "    \n",
    "#     Что происходит?? \n",
    "#     !!!!!!!\n",
    "#     print(logits)\n",
    "    print(model)\n",
    "    logits = model(input_X)\n",
    "# \"logits\" does not change so whyyyyyy\n",
    "    logits = tf.transpose(logits, [1, 0, 2])\n",
    "    print(logits)\n",
    "    print(model)\n",
    "\n",
    "    ctc_loss = tf.reduce_mean(tf.nn.ctc_loss(labels, logits, final_seq_lens))\n",
    "    # ctc_greedy_decoder? merge_repeated=True\n",
    "    decoded, log_prob = tf.nn.ctc_greedy_decoder(logits, final_seq_lens)\n",
    "    ler = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32), labels))\n",
    "\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(ctc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "epoch_save_step=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаемся в начале на коротких данных \n",
    "y_train1=[]\n",
    "X_train1=[]\n",
    "for i in range(len(y)):\n",
    "    if len(y[i]) < 75:\n",
    "        y_train1.append(y[i])\n",
    "        X_train1.append(X[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот отсюда не чего не понятно, код написан на пионе втором , и тензор тоже неизвестно какой версии, я в принципе большую часть всего переделал под третий, а дальше не могу понять что происходит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "[i] LOADING checkpoint checkpoint1/ctc.ckpt-10\n",
      "INFO:tensorflow:Restoring parameters from checkpoint1/ctc.ckpt-10\n",
      "[i] start from epoch 11\n",
      "13\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-2a1cf51e9960>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_decoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mctc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_decoded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch_save_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[i] SAVING snapshot %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msnapshot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loss' is not defined"
     ]
    }
   ],
   "source": [
    "# Произведение вычислительных процессов для частей графа \n",
    "# Бесконенчый цикл, пока выполняется условие\n",
    "# Сессия позволяет хранить значения графа и производить с ними вычисления \n",
    "with tf.Session(graph = graph) as session:\n",
    "    print(\"----------------------------------------------------\")\n",
    "# Храним все переменные модели\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "# Строка, кот. явл. частью названия файла\n",
    "    snapshot = \"ctc\"\n",
    "# Ищет имя последнего чекпоинт-файла\n",
    "# Чекпоинт не содержит описание вычислений в модели\n",
    "# Чекпоинт нужен, когда исходный код использует доступные (сохраненные) значения (веса и индексы) графа\n",
    "# Чекпоинт хранит готовую модель на каком-то шаге \n",
    "# Если папка пустая, то чекпоинт хранит пустое значение \n",
    "    checkpoint = tf.train.latest_checkpoint(checkpoint_dir=\"checkpoint1\")\n",
    "# Определеям значение стартовой эпохи\n",
    "# Количество эпох = количеству обучений на одном дата-сете\n",
    "    last_epoch = 0\n",
    "\n",
    "# Сохранение через каждое заданное кол-во эпох (в нашем случае шаг - 10)\n",
    "# шаг epoch_save_step = 10\n",
    "# После обучения на 10 эпохах делаем сохранение, иначе учимся дальше \n",
    "    if checkpoint:\n",
    "# Произошло сохранение        \n",
    "        print(\"[i] LOADING checkpoint \" + checkpoint)\n",
    "        try:\n",
    "# Обновляем данные с предыдущего сохранения    \n",
    "            saver.restore(session, checkpoint)\n",
    "# Меняем имя файла на \"...\"+(n+1) \n",
    "            last_epoch = int(checkpoint.split('-')[-1]) + 1\n",
    "            print(\"[i] start from epoch %d\" % last_epoch)\n",
    "        except:\n",
    "# Если структура последнего чекпоинта неправильная\n",
    "# Создаем новый чекпоинт              \n",
    "            print(\"[!] incompatible checkpoint, restarting from 0\")\n",
    "    else:\n",
    "# Если нет чекпоинтов (chekpoint = None) \n",
    "# Инициализирум веса и биасы\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "\n",
    "    for epoch in range(last_epoch, num_epochs):\n",
    "# X_batch \n",
    "# Y_batch\n",
    "# seq_lens_batch\n",
    "# y_batch_orig\n",
    "        for X_batch, seq_lens_batch, y_batch, y_batch_orig in batch(X_train1, y_train1, 100):\n",
    "            feed_dict = {\n",
    "                input_X: X_batch,\n",
    "                labels: y_batch,\n",
    "\n",
    "                seq_lens: seq_lens_batch\n",
    "            }\n",
    "            \n",
    "            \n",
    "# train_loss = session.run([ctc_loss])\n",
    "# \n",
    "            train_loss, train_ler, train_decoded, true, _ = session.run([ctc_loss, ler, decoded[0], labels, train_op], feed_dict=feed_dict)\n",
    "        print(\"train_decoded\", train_loss)\n",
    "        if epoch % epoch_save_step == 0 and epoch > 0:\n",
    "                print(\"[i] SAVING snapshot %s\" % snapshot)\n",
    "#                 del tf.get_collection_ref ( ' LAYER_NAME_UIDS ' )[ 0 ]\n",
    "                saver.save(session, \"checkpoint1/\" + snapshot + \".ckpt\", epoch)\n",
    "\n",
    "#         for X_batch, seq_lens_batch, y_batch, y_batch_orig in batch(X_test, y_test, 4):\n",
    "#             feed_dict = {\n",
    "#                 input_X: X_batch,\n",
    "#                 labels: y_batch,\n",
    "#                 seq_lens: seq_lens_batch\n",
    "#             }\n",
    "#             test_loss, test_ler, test_decoded, true = session.run([ctc_loss, ler, decoded[0], labels], feed_dict=feed_dict)\n",
    "#         print(epoch, train_loss, train_ler)#,  test_loss, test_ler)\n",
    "        ret = decode(train_decoded, inv_mapping)[:10]\n",
    "        for i in range(len(ret)):\n",
    "            print(str(ret[i])),\n",
    "        print(time.ctime())\n",
    "        decode1(y_batch_orig[0],inv_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = decode(train_decoded, inv_mapping)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаемся на средних данных (длина предложения меньше 181 символа)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у Вас мощный компьютер, можно обучиться на полных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs=1000\n",
    "# epoch_save_step=5\n",
    "# with tf.Session(graph=graph) as session:\n",
    "\n",
    "#     saver = tf.train.Saver(tf.global_variables())\n",
    "#     snapshot = \"ctc\"\n",
    "#     checkpoint = tf.train.latest_checkpoint(checkpoint_dir=\"checkpoint1\")\n",
    "#     last_epoch = 0\n",
    "\n",
    "#     if checkpoint:\n",
    "#         print(\"[i] LOADING checkpoint \" + checkpoint)\n",
    "#         try:\n",
    "#             saver.restore(session, checkpoint)\n",
    "#             last_epoch = int(checkpoint.split('-')[-1]) + 1\n",
    "#             print(\"[i] start from epoch %d\" % last_epoch)\n",
    "#         except:\n",
    "#             print(\"[!] incompatible checkpoint, restarting from 0\")\n",
    "#     else:\n",
    "#         # Initializate the weights and biases\n",
    "#         tf.global_variables_initializer().run()\n",
    "\n",
    "\n",
    "#     for epoch in range(last_epoch, num_epochs):\n",
    "#         for X_batch, seq_lens_batch, y_batch, y_batch_orig in batch(X, y, 4):\n",
    "#             feed_dict = {\n",
    "#                 input_X: X_batch,\n",
    "#                 labels: y_batch,\n",
    "\n",
    "#                 seq_lens: seq_lens_batch\n",
    "#             }\n",
    "#             train_loss, train_ler, train_decoded, true, _ = session.run([ctc_loss, ler, decoded[0], labels, train_op], feed_dict=feed_dict)\n",
    "#         if epoch % epoch_save_step == 0 and epoch > 0:\n",
    "#                 print(\"[i] SAVING snapshot %s\" % snapshot)\n",
    "# #                 del tf.get_collection_ref ( ' LAYER_NAME_UIDS ' )[ 0 ]\n",
    "#                 saver.save(session, \"checkpoint1/\" + snapshot + \".ckpt\", epoch)\n",
    "\n",
    "# #         for X_batch, seq_lens_batch, y_batch, y_batch_orig in batch(X_test, y_test, 4):\n",
    "# #             feed_dict = {\n",
    "# #                 input_X: X_batch,\n",
    "# #                 labels: y_batch,\n",
    "# #                 seq_lens: seq_lens_batch\n",
    "# #             }\n",
    "# #             test_loss, test_ler, test_decoded, true = session.run([ctc_loss, ler, decoded[0], labels], feed_dict=feed_dict)\n",
    "#         print(epoch, train_loss, train_ler)#,  test_loss, test_ler)\n",
    "#         ret=decode(train_decoded, inv_mapping)[:10]\n",
    "#         for i in range(len(ret)):\n",
    "#             print(str(ret[i])),\n",
    "#         print(time.ctime())\n",
    "#         decode1(y_batch_orig[0],inv_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
